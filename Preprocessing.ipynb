{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Libraries\" data-toc-modified-id=\"Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Libraries</a></span></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing</a></span></li><li><span><a href=\"#Extracting-tweets-from-SQL-database\" data-toc-modified-id=\"Extracting-tweets-from-SQL-database-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Extracting tweets from SQL database</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Word2vec\" data-toc-modified-id=\"Word2vec-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Word2vec</a></span></li></ul></li></ul></li><li><span><a href=\"#Topic-Modeling\" data-toc-modified-id=\"Topic-Modeling-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Topic Modeling</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries \n",
    "\n",
    "    The following Libraries were used in the development of this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\afabi/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\afabi/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\afabi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\afabi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\afabi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "import pyodbc\n",
    "from nltk.tokenize import RegexpTokenizer, WhitespaceTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from string import punctuation\n",
    "import collections\n",
    "from collections import Counter\n",
    "import json \n",
    "\n",
    "import nltk \n",
    "\n",
    "\n",
    "'''Natural Language Processing libraries'''\n",
    "import nltk \n",
    "import gensim\n",
    "import regex as re\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import re, string, unicodedata\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from gensim.models import FastText\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import preprocessor as p\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "\n",
    "# Plotting tools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "The data preprocessing consist of different stages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    \"\"\" Retrieve the narratives from the DataFrame and respectively\n",
    "        store and pre-process it. \n",
    "        \n",
    "        :param df: DataFrame including the reports and the predictor variable. \n",
    "        \n",
    "        \n",
    "        :ivar data: Stores the DataFrame.\n",
    "        :ivar text: Stores the narratives as string.\n",
    "        :ivar corpus: Stores the pre-processed text.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.data = df\n",
    "        self.text = df[\"text\"].astype(str)\n",
    "        self.textPreProcessing()\n",
    "        \n",
    "        \n",
    "    def remove_non_ascii(self, words):\n",
    "        \"\"\"Remove non-ASCII characters from list of tokenized words\n",
    "        \n",
    "        :param words:  List of words to be transformed when removing non_ascii characters.\n",
    "        \n",
    "        :return new_words: List of words after the transformation of removed non_ascii characters.\n",
    "        \n",
    "        \"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "            new_words.append(new_word)\n",
    "        return new_words\n",
    "\n",
    "\n",
    "    def remove_punctuation(self, words):\n",
    "        \"\"\"Remove punctuation from list of tokenized words\n",
    "        \n",
    "        :param words:  List of words that will get remove their punctuations, if any. \n",
    "        \n",
    "        :return new_words: List of transformed words.\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "        return new_words\n",
    "\n",
    "\n",
    "    def stem_words(self, words):\n",
    "        \"\"\"Stem words in list of tokenized words\n",
    "        \n",
    "        :param words:  List of words to be processed. \n",
    "        \n",
    "        :return new_words: List of the received words respective stems.\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        stemmer = LancasterStemmer()\n",
    "        stems = []\n",
    "        for word in words:\n",
    "            stem = stemmer.stem(word)\n",
    "            stems.append(stem)\n",
    "        return stems\n",
    "    \n",
    "    def lemmatize_verbs(self, words):\n",
    "        \"\"\"Lemmatize verbs in list of tokenized words\n",
    "        \n",
    "        :param words:  List of words to be processed. \n",
    "        \n",
    "        :return new_words: List of the received words respective lemmas.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmas = []\n",
    "        for word in words:\n",
    "            lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "            lemmas.append(lemma)\n",
    "        return lemmas\n",
    "    \n",
    "    \n",
    "    \n",
    "    def remove_stopwords(self, words):\n",
    "        \"\"\"Remove common words that have no meaning or importance in the sentence.\n",
    "\n",
    "        :param words:  List of words to be processed and get stop words removed.. \n",
    "\n",
    "        :return new_words: List of words with the stop words already removed.\"\"\"\n",
    "            \n",
    "        \n",
    "        stop_words = set(stopwords.words('spanish')) \n",
    "        stop_words1 = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "        \n",
    "        for word in stop_words:\n",
    "            if word in words:\n",
    "                words.remove(word)\n",
    "                \n",
    "        for word in stop_words1:\n",
    "            if word in words:\n",
    "                words.remove(word)\n",
    "                \n",
    "        return words\n",
    "\n",
    "\n",
    "    \n",
    "    def normalize(self, words):\n",
    "        words = self.remove_non_ascii(words)\n",
    "        words = self.remove_stopwords(words)\n",
    "        words = self.remove_punctuation(words)\n",
    "        words = self.lemmatize_verbs(words)\n",
    "        return words\n",
    "    \n",
    "    \n",
    "    def textPreProcessing(self):\n",
    "        \"\"\"Pre-process the text, normalize and clean it.\n",
    "        The function stores the cleaned text in the self.data\n",
    "        attribute. \"\"\"\n",
    "        p.set_options(p.OPT.URL,p.OPT.MENTION,p.OPT.HASHTAG,p.OPT.RESERVED,p.OPT.SMILEY,p.OPT.NUMBER)\n",
    "\n",
    "\n",
    "        clean_text = []\n",
    "\n",
    "        for narrative in self.text:\n",
    "            sentence = p.clean(narrative)\n",
    "            #sentence = re.sub('RT @[\\w_]+:', '', sentence)\n",
    "\n",
    "            #sentence = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', sentence)\n",
    "            sentence = word_tokenize(sentence)\n",
    "            sentence = self.normalize(sentence)\n",
    "                \n",
    "                \n",
    "            clean_text.append(sentence)\n",
    "            \n",
    "            \n",
    "                    \n",
    "        print(len(self.text), len(clean_text))\n",
    "        self.data[\"clean_text\"] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatTweets(table):\n",
    "    tweets = ''\n",
    "    c = 0\n",
    "    for row in df.tweets:\n",
    "        if(c == 0):\n",
    "            c+= 1\n",
    "            tweets = pd.DataFrame(json.loads(row))\n",
    "        else:\n",
    "            tweets = pd.concat([tweets, pd.DataFrame(json.loads(row))], axis=0, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    return tweets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting tweets from SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'sqldatamining.database.windows.net'\n",
    "database = 'SNA'\n",
    "username = 'UserAdmin'\n",
    "password = 'Machomen123'   \n",
    "driver= '{ODBC Driver 13 for SQL Server}'\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={ODBC Driver 13 for SQL Server};SERVER=sqldatamining.database.windows.net,1433', user='UserAdmin' , password='Machomen123', database='SNA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = cursor.execute(\"SELECT * from dbo.Users1 \").fetchmany(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame((tuple(t) for t in rows), columns=['id', \n",
    " 'author',\n",
    " 'created_at',\n",
    " 'location',\n",
    " 'description',\n",
    " 'verified',\n",
    " 'followers',\n",
    " 'following',\n",
    " 'favourites_count',\n",
    " 'statuses_count',\n",
    " 'lang',\n",
    " 'tweets',\n",
    " 'following_json',\n",
    " 'followers_json']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweets</th>\n",
       "      <th>following_json</th>\n",
       "      <th>followers_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2284857094</td>\n",
       "      <td>themoonisironic</td>\n",
       "      <td>2014-01-16 01:10:33</td>\n",
       "      <td>‘97 // they/them // ????????</td>\n",
       "      <td>where there is hope, there are trials // art: ...</td>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>516</td>\n",
       "      <td>121166</td>\n",
       "      <td>36377</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1356030533780824069, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 1387079251476815875, \"author\": \"rikuno...</td>\n",
       "      <td>[{\"id\": 1384297303129825284, \"author\": \"bts123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>834324620</td>\n",
       "      <td>bbelita23</td>\n",
       "      <td>2012-09-19 23:21:48</td>\n",
       "      <td>spooky town, PR</td>\n",
       "      <td>just put it out into the universe</td>\n",
       "      <td>False</td>\n",
       "      <td>670</td>\n",
       "      <td>443</td>\n",
       "      <td>33428</td>\n",
       "      <td>92917</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1356026926134140928, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 2513536418, \"author\": \"Kvn_Astacio\", \"...</td>\n",
       "      <td>[{\"id\": 1289669319526420482, \"author\": \"keviin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175521394</td>\n",
       "      <td>Stormfocus18</td>\n",
       "      <td>2010-08-06 21:03:08</td>\n",
       "      <td>Puerto Rico_Island</td>\n",
       "      <td>Loving #MewGulf and #KristSingto, amante de la...</td>\n",
       "      <td>False</td>\n",
       "      <td>199</td>\n",
       "      <td>187</td>\n",
       "      <td>6497</td>\n",
       "      <td>38945</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"id\": 1387677517822054400, \"author\": \"tinest...</td>\n",
       "      <td>[{\"id\": 1387677517822054400, \"author\": \"tinest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685491040</td>\n",
       "      <td>CoraimaINegron</td>\n",
       "      <td>2013-08-20 10:48:59</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>“El karma te lo devolverá todo, excepto a la m...</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>203</td>\n",
       "      <td>1336</td>\n",
       "      <td>1565</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1283388114661244934, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 299932350, \"author\": \"DMcIntyreWWE\", \"...</td>\n",
       "      <td>[{\"id\": 713749428935462916, \"author\": \"DavidRo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1388202983964520449</td>\n",
       "      <td>Personn34091581</td>\n",
       "      <td>2021-04-30 18:46:05</td>\n",
       "      <td>Costa brava</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"id\": 560803492, \"author\": \"UrbanLePharaon\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1685491040</td>\n",
       "      <td>CoraimaINegron</td>\n",
       "      <td>2013-08-20 10:48:59</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>“El karma te lo devolverá todo, excepto a la m...</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>203</td>\n",
       "      <td>1336</td>\n",
       "      <td>1565</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1283388114661244934, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 299932350, \"author\": \"DMcIntyreWWE\", \"...</td>\n",
       "      <td>[{\"id\": 713749428935462916, \"author\": \"DavidRo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1388202983964520449</td>\n",
       "      <td>Personn34091581</td>\n",
       "      <td>2021-04-30 18:46:05</td>\n",
       "      <td>Costa brava</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"id\": 560803492, \"author\": \"UrbanLePharaon\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>908687401123553280</td>\n",
       "      <td>rsantanafonseca</td>\n",
       "      <td>2017-09-15 13:42:13</td>\n",
       "      <td>COPU, UPRRP</td>\n",
       "      <td>19 (+3) | ?????? | Pop culture enthusiast, soc...</td>\n",
       "      <td>False</td>\n",
       "      <td>891</td>\n",
       "      <td>620</td>\n",
       "      <td>121676</td>\n",
       "      <td>124488</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"id\": 755882683, \"author\": \"_vidalysrms\", \"c...</td>\n",
       "      <td>[{\"id\": 1344047685716815872, \"author\": \"LeQuee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1346688657365889024</td>\n",
       "      <td>SJCiudadCapital</td>\n",
       "      <td>2021-01-06 05:23:04</td>\n",
       "      <td></td>\n",
       "      <td>Cuenta Oficial de la Ciudad Capital de Puerto ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2915</td>\n",
       "      <td>183</td>\n",
       "      <td>291</td>\n",
       "      <td>1157</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1355954464436473856, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 1309256724830969857, \"author\": \"estefa...</td>\n",
       "      <td>[{\"id\": 1271152649304518657, \"author\": \"JCruz_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>521836439</td>\n",
       "      <td>Angelicv_G</td>\n",
       "      <td>2012-03-12 01:12:16</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>UT • yo no sé que poner aquí??</td>\n",
       "      <td>False</td>\n",
       "      <td>962</td>\n",
       "      <td>519</td>\n",
       "      <td>115665</td>\n",
       "      <td>130883</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1356041673227313154, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 1192074658994180096, \"author\": \"Nsnili...</td>\n",
       "      <td>[{\"id\": 1383464766283280389, \"author\": \"geegee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           author          created_at  \\\n",
       "0           2284857094  themoonisironic 2014-01-16 01:10:33   \n",
       "1            834324620        bbelita23 2012-09-19 23:21:48   \n",
       "2            175521394     Stormfocus18 2010-08-06 21:03:08   \n",
       "3           1685491040   CoraimaINegron 2013-08-20 10:48:59   \n",
       "4  1388202983964520449  Personn34091581 2021-04-30 18:46:05   \n",
       "5           1685491040   CoraimaINegron 2013-08-20 10:48:59   \n",
       "6  1388202983964520449  Personn34091581 2021-04-30 18:46:05   \n",
       "7   908687401123553280  rsantanafonseca 2017-09-15 13:42:13   \n",
       "8  1346688657365889024  SJCiudadCapital 2021-01-06 05:23:04   \n",
       "9            521836439       Angelicv_G 2012-03-12 01:12:16   \n",
       "\n",
       "                       location  \\\n",
       "0  ‘97 // they/them // ????????   \n",
       "1              spooky town, PR    \n",
       "2           Puerto Rico_Island    \n",
       "3                   Puerto Rico   \n",
       "4                   Costa brava   \n",
       "5                   Puerto Rico   \n",
       "6                   Costa brava   \n",
       "7                   COPU, UPRRP   \n",
       "8                                 \n",
       "9                   Puerto Rico   \n",
       "\n",
       "                                         description  verified  followers  \\\n",
       "0  where there is hope, there are trials // art: ...     False        101   \n",
       "1                  just put it out into the universe     False        670   \n",
       "2  Loving #MewGulf and #KristSingto, amante de la...     False        199   \n",
       "3  “El karma te lo devolverá todo, excepto a la m...     False         64   \n",
       "4                                                        False          0   \n",
       "5  “El karma te lo devolverá todo, excepto a la m...     False         64   \n",
       "6                                                        False          0   \n",
       "7  19 (+3) | ?????? | Pop culture enthusiast, soc...     False        891   \n",
       "8  Cuenta Oficial de la Ciudad Capital de Puerto ...     False       2915   \n",
       "9                     UT • yo no sé que poner aquí??     False        962   \n",
       "\n",
       "   following  favourites_count  statuses_count  lang  \\\n",
       "0        516            121166           36377  None   \n",
       "1        443             33428           92917  None   \n",
       "2        187              6497           38945  None   \n",
       "3        203              1336            1565  None   \n",
       "4          2                 9               7  None   \n",
       "5        203              1336            1565  None   \n",
       "6          2                 9               7  None   \n",
       "7        620            121676          124488  None   \n",
       "8        183               291            1157  None   \n",
       "9        519            115665          130883  None   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  [{\"id\": 1356030533780824069, \"created_at\": \"20...   \n",
       "1  [{\"id\": 1356026926134140928, \"created_at\": \"20...   \n",
       "2                                                 []   \n",
       "3  [{\"id\": 1283388114661244934, \"created_at\": \"20...   \n",
       "4                                                 []   \n",
       "5  [{\"id\": 1283388114661244934, \"created_at\": \"20...   \n",
       "6                                                 []   \n",
       "7                                                 []   \n",
       "8  [{\"id\": 1355954464436473856, \"created_at\": \"20...   \n",
       "9  [{\"id\": 1356041673227313154, \"created_at\": \"20...   \n",
       "\n",
       "                                      following_json  \\\n",
       "0  [{\"id\": 1387079251476815875, \"author\": \"rikuno...   \n",
       "1  [{\"id\": 2513536418, \"author\": \"Kvn_Astacio\", \"...   \n",
       "2  [{\"id\": 1387677517822054400, \"author\": \"tinest...   \n",
       "3  [{\"id\": 299932350, \"author\": \"DMcIntyreWWE\", \"...   \n",
       "4  [{\"id\": 560803492, \"author\": \"UrbanLePharaon\",...   \n",
       "5  [{\"id\": 299932350, \"author\": \"DMcIntyreWWE\", \"...   \n",
       "6  [{\"id\": 560803492, \"author\": \"UrbanLePharaon\",...   \n",
       "7  [{\"id\": 755882683, \"author\": \"_vidalysrms\", \"c...   \n",
       "8  [{\"id\": 1309256724830969857, \"author\": \"estefa...   \n",
       "9  [{\"id\": 1192074658994180096, \"author\": \"Nsnili...   \n",
       "\n",
       "                                      followers_json  \n",
       "0  [{\"id\": 1384297303129825284, \"author\": \"bts123...  \n",
       "1  [{\"id\": 1289669319526420482, \"author\": \"keviin...  \n",
       "2  [{\"id\": 1387677517822054400, \"author\": \"tinest...  \n",
       "3  [{\"id\": 713749428935462916, \"author\": \"DavidRo...  \n",
       "4                                                 []  \n",
       "5  [{\"id\": 713749428935462916, \"author\": \"DavidRo...  \n",
       "6                                                 []  \n",
       "7  [{\"id\": 1344047685716815872, \"author\": \"LeQuee...  \n",
       "8  [{\"id\": 1271152649304518657, \"author\": \"JCruz_...  \n",
       "9  [{\"id\": 1383464766283280389, \"author\": \"geegee...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "435940\n",
      "181519\n",
      "2\n",
      "34422\n",
      "2\n",
      "34422\n",
      "2\n",
      "2\n",
      "68260\n",
      "331733\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for tweets in df.tweets:\n",
    "    print(len(tweets))\n",
    "    if(len(tweets) == 2):\n",
    "        df.drop([index], inplace=True, axis=0)\n",
    "    \n",
    "    index+=1\n",
    "    \n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "index = 0\n",
    "temp_user = \"\"\n",
    "for user in df.author:\n",
    "    if(user != temp_user):\n",
    "        print(\"a\")\n",
    "        temp_user = user \n",
    "    else:\n",
    "        df.drop([index], inplace=True, axis=0)\n",
    "    \n",
    "    \n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweets</th>\n",
       "      <th>following_json</th>\n",
       "      <th>followers_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2284857094</td>\n",
       "      <td>themoonisironic</td>\n",
       "      <td>2014-01-16 01:10:33</td>\n",
       "      <td>‘97 // they/them // ????????</td>\n",
       "      <td>where there is hope, there are trials // art: ...</td>\n",
       "      <td>False</td>\n",
       "      <td>101</td>\n",
       "      <td>516</td>\n",
       "      <td>121166</td>\n",
       "      <td>36377</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1356030533780824069, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 1387079251476815875, \"author\": \"rikuno...</td>\n",
       "      <td>[{\"id\": 1384297303129825284, \"author\": \"bts123...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          id           author          created_at  \\\n",
       "0      0  2284857094  themoonisironic 2014-01-16 01:10:33   \n",
       "\n",
       "                       location  \\\n",
       "0  ‘97 // they/them // ????????   \n",
       "\n",
       "                                         description  verified  followers  \\\n",
       "0  where there is hope, there are trials // art: ...     False        101   \n",
       "\n",
       "   following  favourites_count  statuses_count  lang  \\\n",
       "0        516            121166           36377  None   \n",
       "\n",
       "                                              tweets  \\\n",
       "0  [{\"id\": 1356030533780824069, \"created_at\": \"20...   \n",
       "\n",
       "                                      following_json  \\\n",
       "0  [{\"id\": 1387079251476815875, \"author\": \"rikuno...   \n",
       "\n",
       "                                      followers_json  \n",
       "0  [{\"id\": 1384297303129825284, \"author\": \"bts123...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>geo</th>\n",
       "      <th>user</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356030533780824069</td>\n",
       "      <td>2021-02-01T00:04:07</td>\n",
       "      <td>RT @geheichou: Childe I told you to stop\\n#Gen...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>themoonisironic</td>\n",
       "      <td>4929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1355996223753383939</td>\n",
       "      <td>2021-01-31T21:47:47</td>\n",
       "      <td>i’m also obsessed with a curse stemming from l...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>themoonisironic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1355995462784978944</td>\n",
       "      <td>2021-01-31T21:44:46</td>\n",
       "      <td>i also really like yuta - he’s sweet but terri...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>themoonisironic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1355995461820137472</td>\n",
       "      <td>2021-01-31T21:44:45</td>\n",
       "      <td>kk, finished jjk 0\\nit was really interesting ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>themoonisironic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1355991939976454146</td>\n",
       "      <td>2021-01-31T21:30:46</td>\n",
       "      <td>@hinosreis no, jujutsu kaisen!! it’s off next ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>themoonisironic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           created_at  \\\n",
       "0  1356030533780824069  2021-02-01T00:04:07   \n",
       "1  1355996223753383939  2021-01-31T21:47:47   \n",
       "2  1355995462784978944  2021-01-31T21:44:46   \n",
       "3  1355995461820137472  2021-01-31T21:44:45   \n",
       "4  1355991939976454146  2021-01-31T21:30:46   \n",
       "\n",
       "                                                text coordinates   geo  \\\n",
       "0  RT @geheichou: Childe I told you to stop\\n#Gen...        None  None   \n",
       "1  i’m also obsessed with a curse stemming from l...        None  None   \n",
       "2  i also really like yuta - he’s sweet but terri...        None  None   \n",
       "3  kk, finished jjk 0\\nit was really interesting ...        None  None   \n",
       "4  @hinosreis no, jujutsu kaisen!! it’s off next ...        None  None   \n",
       "\n",
       "              user  retweet_count  favorite_count  \n",
       "0  themoonisironic           4929               0  \n",
       "1  themoonisironic              0               0  \n",
       "2  themoonisironic              0               0  \n",
       "3  themoonisironic              0               0  \n",
       "4  themoonisironic              0               1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = concatTweets(df)\n",
    "\n",
    "\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(documento.data[\"clean_text\"], min_count=0, workers=20, window=2,  alpha=0.02, hs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = dict({})\n",
    "for idx, key in enumerate(model.wv.key_to_index):\n",
    "    my_dict[key] = model.wv[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>vectorized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>: El ajusta la magnitud a , en el límite de pr...</td>\n",
       "      <td>[El, ajusta, magnitud, limite, producir, tsunami]</td>\n",
       "      <td>[[-0.017272485, 0.008652826, 0.007515971, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>: “ Van a seguir ocurriendo eventos fuertes. H...</td>\n",
       "      <td>[Van, seguir, ocurriendo, eventos, fuertes, Ha...</td>\n",
       "      <td>[[-0.0027897793, -0.0016228552, -0.007687815, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>: Casa colapsada en Yauco.</td>\n",
       "      <td>[Casa, colapsada, Yauco]</td>\n",
       "      <td>[[0.008535036, 0.013252284, 0.00035941493, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>: “Las réplicas podrían ser de magnitud mayor ...</td>\n",
       "      <td>[Las, replicas, podrian, ser, magnitud, mayor,...</td>\n",
       "      <td>[[0.0029013832, -0.0027108788, -0.0015446608, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>: PRELIMINAR -01-06 :58:03 No hay Aviso, Adver...</td>\n",
       "      <td>[PRELIMINAR, 06, 5803, No, Aviso, Advertencia,...</td>\n",
       "      <td>[[-0.0127012255, 0.0040803654, 0.009027934, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "113  : El ajusta la magnitud a , en el límite de pr...   \n",
       "114  : “ Van a seguir ocurriendo eventos fuertes. H...   \n",
       "115                         : Casa colapsada en Yauco.   \n",
       "116  : “Las réplicas podrían ser de magnitud mayor ...   \n",
       "117  : PRELIMINAR -01-06 :58:03 No hay Aviso, Adver...   \n",
       "\n",
       "                                            clean_text  \\\n",
       "113  [El, ajusta, magnitud, limite, producir, tsunami]   \n",
       "114  [Van, seguir, ocurriendo, eventos, fuertes, Ha...   \n",
       "115                           [Casa, colapsada, Yauco]   \n",
       "116  [Las, replicas, podrian, ser, magnitud, mayor,...   \n",
       "117  [PRELIMINAR, 06, 5803, No, Aviso, Advertencia,...   \n",
       "\n",
       "                                       vectorized_text  \n",
       "113  [[-0.017272485, 0.008652826, 0.007515971, 0.00...  \n",
       "114  [[-0.0027897793, -0.0016228552, -0.007687815, ...  \n",
       "115  [[0.008535036, 0.013252284, 0.00035941493, 0.0...  \n",
       "116  [[0.0029013832, -0.0027108788, -0.0015446608, ...  \n",
       "117  [[-0.0127012255, 0.0040803654, 0.009027934, -0...  "
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectores = []\n",
    "for a in documento.data.clean_text:\n",
    "    t  = []\n",
    "    for word in a:\n",
    "        try:\n",
    "            t.append(my_dict[word])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    vectores.append(t)\n",
    "        \n",
    "documento.data[\"vectorized_text\"] = vectores\n",
    "documento.data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>followers</th>\n",
       "      <th>following</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweets</th>\n",
       "      <th>following_json</th>\n",
       "      <th>followers_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1685491040</td>\n",
       "      <td>CoraimaINegron</td>\n",
       "      <td>2013-08-20 10:48:59</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>“El karma te lo devolverá todo, excepto a la m...</td>\n",
       "      <td>False</td>\n",
       "      <td>64</td>\n",
       "      <td>203</td>\n",
       "      <td>1336</td>\n",
       "      <td>1565</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1283388114661244934, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 299932350, \"author\": \"DMcIntyreWWE\", \"...</td>\n",
       "      <td>[{\"id\": 713749428935462916, \"author\": \"DavidRo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1388202983964520449</td>\n",
       "      <td>Personn34091581</td>\n",
       "      <td>2021-04-30 18:46:05</td>\n",
       "      <td>Costa brava</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"id\": 560803492, \"author\": \"UrbanLePharaon\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>908687401123553280</td>\n",
       "      <td>rsantanafonseca</td>\n",
       "      <td>2017-09-15 13:42:13</td>\n",
       "      <td>COPU, UPRRP</td>\n",
       "      <td>19 (+3) | ?????? | Pop culture enthusiast, soc...</td>\n",
       "      <td>False</td>\n",
       "      <td>891</td>\n",
       "      <td>620</td>\n",
       "      <td>121676</td>\n",
       "      <td>124488</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"id\": 755882683, \"author\": \"_vidalysrms\", \"c...</td>\n",
       "      <td>[{\"id\": 1344047685716815872, \"author\": \"LeQuee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1346688657365889024</td>\n",
       "      <td>SJCiudadCapital</td>\n",
       "      <td>2021-01-06 05:23:04</td>\n",
       "      <td></td>\n",
       "      <td>Cuenta Oficial de la Ciudad Capital de Puerto ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2915</td>\n",
       "      <td>183</td>\n",
       "      <td>291</td>\n",
       "      <td>1157</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1355954464436473856, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 1309256724830969857, \"author\": \"estefa...</td>\n",
       "      <td>[{\"id\": 1271152649304518657, \"author\": \"JCruz_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>521836439</td>\n",
       "      <td>Angelicv_G</td>\n",
       "      <td>2012-03-12 01:12:16</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>UT • yo no sé que poner aquí??</td>\n",
       "      <td>False</td>\n",
       "      <td>962</td>\n",
       "      <td>519</td>\n",
       "      <td>115665</td>\n",
       "      <td>130883</td>\n",
       "      <td>None</td>\n",
       "      <td>[{\"id\": 1356041673227313154, \"created_at\": \"20...</td>\n",
       "      <td>[{\"id\": 1192074658994180096, \"author\": \"Nsnili...</td>\n",
       "      <td>[{\"id\": 1383464766283280389, \"author\": \"geegee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           author          created_at     location  \\\n",
       "5           1685491040   CoraimaINegron 2013-08-20 10:48:59  Puerto Rico   \n",
       "6  1388202983964520449  Personn34091581 2021-04-30 18:46:05  Costa brava   \n",
       "7   908687401123553280  rsantanafonseca 2017-09-15 13:42:13  COPU, UPRRP   \n",
       "8  1346688657365889024  SJCiudadCapital 2021-01-06 05:23:04                \n",
       "9            521836439       Angelicv_G 2012-03-12 01:12:16  Puerto Rico   \n",
       "\n",
       "                                         description  verified  followers  \\\n",
       "5  “El karma te lo devolverá todo, excepto a la m...     False         64   \n",
       "6                                                        False          0   \n",
       "7  19 (+3) | ?????? | Pop culture enthusiast, soc...     False        891   \n",
       "8  Cuenta Oficial de la Ciudad Capital de Puerto ...     False       2915   \n",
       "9                     UT • yo no sé que poner aquí??     False        962   \n",
       "\n",
       "   following  favourites_count  statuses_count  lang  \\\n",
       "5        203              1336            1565  None   \n",
       "6          2                 9               7  None   \n",
       "7        620            121676          124488  None   \n",
       "8        183               291            1157  None   \n",
       "9        519            115665          130883  None   \n",
       "\n",
       "                                              tweets  \\\n",
       "5  [{\"id\": 1283388114661244934, \"created_at\": \"20...   \n",
       "6                                                 []   \n",
       "7                                                 []   \n",
       "8  [{\"id\": 1355954464436473856, \"created_at\": \"20...   \n",
       "9  [{\"id\": 1356041673227313154, \"created_at\": \"20...   \n",
       "\n",
       "                                      following_json  \\\n",
       "5  [{\"id\": 299932350, \"author\": \"DMcIntyreWWE\", \"...   \n",
       "6  [{\"id\": 560803492, \"author\": \"UrbanLePharaon\",...   \n",
       "7  [{\"id\": 755882683, \"author\": \"_vidalysrms\", \"c...   \n",
       "8  [{\"id\": 1309256724830969857, \"author\": \"estefa...   \n",
       "9  [{\"id\": 1192074658994180096, \"author\": \"Nsnili...   \n",
       "\n",
       "                                      followers_json  \n",
       "5  [{\"id\": 713749428935462916, \"author\": \"DavidRo...  \n",
       "6                                                 []  \n",
       "7  [{\"id\": 1344047685716815872, \"author\": \"LeQuee...  \n",
       "8  [{\"id\": 1271152649304518657, \"author\": \"JCruz_...  \n",
       "9  [{\"id\": 1383464766283280389, \"author\": \"geegee...  "
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignTopics(users, tweetss):\n",
    "    topics = userSubSets(tweetss)\n",
    "   \n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    return users\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def userSubSets(tweets_df):\n",
    "    user = ''\n",
    "    topics = []\n",
    "    for instance in tweets_df.user:\n",
    "        if(user != instance):\n",
    "            print(instance)\n",
    "            user = instance\n",
    "            actual_user =  tweets_df['user']== user\n",
    "            user_subset = tweets_df[actual_user]\n",
    "            topics.append(topicModeling(user_subset))\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "            \n",
    "    return topics\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "def topicModeling(user_subset):\n",
    "    tweets = Document(pd.DataFrame(user_subset))\n",
    "    #id2word = corpora.Dictionary(tweets.data.clean_text)\n",
    "\n",
    "    # Create Corpus\n",
    "    #texts = tweets.data.clean_text\n",
    "\n",
    "    # Term Document Frequency\n",
    "    #corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    \n",
    "    covid = '''covid pandemia coronavirus vacuna cuarentena virus mascara propagacion'''\n",
    "    \n",
    "    string1 = covid\n",
    "    words = string1.split()\n",
    "    covid = \" \".join(sorted(set(words), key=words.index))\n",
    "    \n",
    "    \n",
    "    e_scores = get_scores(covid, tweets.data.clean_text)\n",
    "    print(e_scores)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_scores(group,tweets):\n",
    "    scores = []\n",
    "    for tweet in tweets:\n",
    "        s = jaccard_similarity(group, tweet)\n",
    "        scores.append(s)\n",
    "    return scores\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3773 3773\n"
     ]
    }
   ],
   "source": [
    "tweets = Document(x)\n",
    "\n",
    "covid = '''covid pandemia coronavirus vacuna cuarentena virus mascara propagacion'''\n",
    "politica = '''gobierno politica ppd pnp pip independentista popular wanda pierluisi gobernador senado camara legislador proyecto '''\n",
    "emociones = '''depresion ansiedad felicidad emocion salud mental tristesa triste alegre contento ansioso'''\n",
    "eventos = '''terremoto tsunami huracan lluvia calor tormenta '''\n",
    "\n",
    "string1 = covid\n",
    "words = string1.split()\n",
    "covid = \" \".join(sorted(set(words), key=words.index))\n",
    "\n",
    "string1 = politica\n",
    "words = string1.split()\n",
    "politica = \" \".join(sorted(set(words), key=words.index))\n",
    "\n",
    "string1 = emociones\n",
    "words = string1.split()\n",
    "emociones = \" \".join(sorted(set(words), key=words.index))\n",
    "\n",
    "string1 = eventos\n",
    "words = string1.split()\n",
    "eventos = \" \".join(sorted(set(words), key=words.index))\n",
    "\n",
    "\n",
    "covid_scores = get_scores(covid, tweets.data.clean_text)\n",
    "politica_scores = get_scores(politica, tweets.data.clean_text)\n",
    "emociones_scores = get_scores(emociones, tweets.data.clean_text)\n",
    "eventos_scores = get_scores(eventos, tweets.data.clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             names  covid_scores  politica_scores  emociones_scores  \\\n",
      "0  themoonisironic           0.0              0.0               0.0   \n",
      "1  themoonisironic           0.0              0.0               0.0   \n",
      "2  themoonisironic           0.0              0.0               0.0   \n",
      "3  themoonisironic           0.0              0.0               0.0   \n",
      "4  themoonisironic           0.0              0.0               0.0   \n",
      "\n",
      "   eventos_scores  \n",
      "0             0.0  \n",
      "1             0.0  \n",
      "2             0.0  \n",
      "3             0.0  \n",
      "4             0.0  \n"
     ]
    }
   ],
   "source": [
    "# create a jaccard scored df.\n",
    "data  = {'names':x.user.to_list(),       'covid_scores':covid_scores,\n",
    "         'politica_scores': politica_scores, 'emociones_scores':emociones_scores, 'eventos_scores':eventos_scores}\n",
    "scores_df = pd.DataFrame(data)\n",
    "#assign classes based on highest score\n",
    "def get_classes(l1, l2, l3, l4):\n",
    "    econ = []\n",
    "    socio = []\n",
    "    cul = []\n",
    "    heal = []\n",
    "    for i, j, k, l in zip(l1, l2, l3, l4):\n",
    "        m = max(i, j, k, l)\n",
    "        if m == i:\n",
    "            econ.append(1)\n",
    "        else:\n",
    "            econ.append(0)\n",
    "        if m == j:\n",
    "            socio.append(1)\n",
    "        else:\n",
    "            socio.append(0)        \n",
    "        if m == k:\n",
    "            cul.append(1)\n",
    "        else:\n",
    "            cul.append(0)  \n",
    "        if m == l:\n",
    "            heal.append(1)\n",
    "        else:\n",
    "            heal.append(0)   \n",
    "            \n",
    "    return econ, socio, cul, heal\n",
    "\n",
    "print(scores_df.head())\n",
    "l1 = scores_df.covid_scores.to_list()\n",
    "l2 = scores_df.politica_scores.to_list()\n",
    "l3 = scores_df.emociones_scores.to_list()\n",
    "l4 = scores_df.eventos_scores.to_list()\n",
    "econ, socio, cul, heal = get_classes(l1, l2, l3, l4)\n",
    "\n",
    "data = {'name': scores_df.names.to_list(), 'economic':econ, 'social':socio, 'culture':cul, 'health': heal}\n",
    "class_df = pd.DataFrame(data)\n",
    "#grouping the tweets by username\n",
    "new_groups_df = class_df.groupby(['name']).sum()\n",
    "#add a new totals column\n",
    "new_groups_df['total'] = new_groups_df['health'] + new_groups_df['culture'] + new_groups_df['social'] +  new_groups_df['economic']\n",
    "#add a new totals row\n",
    "new_groups_df.loc[\"Total\"] = new_groups_df.sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>economic</th>\n",
       "      <th>social</th>\n",
       "      <th>culture</th>\n",
       "      <th>health</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Angelicv_G</th>\n",
       "      <td>1094</td>\n",
       "      <td>1091</td>\n",
       "      <td>1085</td>\n",
       "      <td>1167</td>\n",
       "      <td>4437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoraimaINegron</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>118</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJCiudadCapital</th>\n",
       "      <td>198</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>208</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbelita23</th>\n",
       "      <td>688</td>\n",
       "      <td>690</td>\n",
       "      <td>686</td>\n",
       "      <td>713</td>\n",
       "      <td>2777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>themoonisironic</th>\n",
       "      <td>1191</td>\n",
       "      <td>1182</td>\n",
       "      <td>1179</td>\n",
       "      <td>1517</td>\n",
       "      <td>5069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 economic  social  culture  health  total\n",
       "name                                                     \n",
       "Angelicv_G           1094    1091     1085    1167   4437\n",
       "CoraimaINegron        109     109      109     118    445\n",
       "SJCiudadCapital       198     197      195     208    798\n",
       "bbelita23             688     690      686     713   2777\n",
       "themoonisironic      1191    1182     1179    1517   5069"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_groups_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud \n",
    "\n",
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "from google.cloud.language_v1 import types\n",
    "\n",
    "\n",
    "\n",
    "client = language.LanguageServiceClient()\n",
    "\n",
    "document = types.Document(tweets.data.clean_text,\n",
    "           type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "annotations = client.analyze_sentiment(document=document,\n",
    "                                       encoding_type='UTF32', timeout=600)\n",
    "\n",
    "sentences = []\n",
    "for s in annotations.sentences:\n",
    "    sentences.append((s.text.content, s.sentiment.score, s.sentiment.magnitude))\n",
    "\n",
    "df = pd.DataFrame(sentences, columns=['sentence', 'score', 'magnitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
